---
layout: homepage

---

## About Me
I'm a research assistant in the <a href="https://slab-lab.github.io/" target="_blank">Speech, Learning, and the Brain (SLaB) Lab</a> at the Hong Kong University of Science and Technology, working under the mentorship of Prof. <a href="https://sites.google.com/site/qinzhenquentin/" target="_blank">Quentin Zhen QIN</a>. Before joining the lab, I was supervised by Prof. <a href="https://www.researchgate.net/profile/Hao-Zhang-39" target="_blank">Hao ZHANG</a> for my undergraduate studies. I'm interested in experimental phonetics, second/foreign language acquisition, and psycholinguistics.

## Research Interests
- Production and Perception of Non-native Languages
- Cross-domain Transfer Effects between Music and Language
- Age-related Differences in Language Learning


## Education
**BA in English** at Shandong University (Average Grade: 88.71/100)  [2020-2024]

**GPA in discipline-related coursework**: 93.25/100<br>
English Phonetics (96), Phonetics and Brain Science (Excellent), Experimental Phonetics (92), Experimental Methods and 
the Application of Instruments in Phonetics (95), Cognitive Neuroscience Experiment (90), Corpus Linguistics (93), 
Python and Natural Language Processing (94)


## Appointment

<ul class="research-list">
  <li>
    <strong>Research Assistant</strong><br>
    <span class="date">[Aug. 2024–Present]</span><br>
    Hong Kong University of Science and Technology<br>
    Supervisor: Dr. Quentin Zhen Qin
  </li>

  <li>
    <strong>Research Assistant</strong><br>
    <span class="date">[Jun. 2023–Jun. 2024]</span><br>
    Shandong University<br>
    Supervisor: Dr. Hao Zhang
  </li>
</ul>



## Publications & Presentations

### Journal Articles

Zhang, H., & **Liang, J.** *(co-first author).* Benefits of melodic training on the production and perception of Cantonese level tones by Korean and Chinese older adults. *(Manuscript in preparation).*

Tremblay, A., Broersma, M., Cho, T., Qin, Q. Z., Kim, H., & **Liang, J.** (preprint). Towards an attentional theory of second-language speech perception: Evidence from cue ecology. *PsyArXiv preprint.* <a href="https://osf.io/preprints/psyarxiv/4y3rm_v1" target="_blank">https://osf.io/preprints/psyarxiv/4y3rm_v1</a>

Tremblay, A., Broersma, M., Cho, T., Qin, Q. Z., Kim, H., & **Liang, J.** (submitted). Towards an attentional theory of second-language speech perception: Evidence from cue ecology. *Cognition.*

**Liang, J.**, Zhang, H., Ma, W., & Ding, H. (2025). Effect of musical aptitude on the perception of English vowels: An eye-tracking investigation among native Mandarin speakers. <em>Journal of Speech, Language, and Hearing Research</em>, 68(10), 5021–5038. <a href="https://doi.org/10.1044/2025_JSLHR-24-00916" target="_blank">https://doi.org/10.1044/2025_JSLHR-24-00916</a> [<a href="assets/files/JYL.pdf" target="_blank">PDF</a>]

### Conference Presentations

**Liang, J.**, Lai, S., Zhang, C., & Qin, Q. Z. (submitted). Daytime naps selectively consolidate Cantonese tones in non-tonal learners. <em>The Hanyang International Symposium on Phonetics and Cognitive Sciences of Language (HISPhonCog 2026)</em>, Seoul, South Korea.

Wang, Y., **Liang, J.**, Myachykov, A., & Qin, Q. Z. (submitted). Multilingual experience predicts attentional control in dichotic listening among older adults: The mediating role of socioeconomic status. <em>The Hanyang International Symposium on Phonetics and Cognitive Sciences of Language (HISPhonCog 2026)</em>, Seoul, South Korea.

Tremblay, A., Broersma, M., Cho, T., Kim, H., Qin, Q. Z., **Liang, J.**, Nuñez, A., & Terrazas, F. (2025). Cross-linguistic transfer in lexical stress perception: A cue-weighting typology. <em>The 6th joint meeting of the Acoustical Society of America and Acoustical Society of Japan</em>, Honolulu, HI. Poster Presentation.

Wang, Y., **Liang, J.**, & Qin, Q. Z. (2025). The role of bilingual experiences on attentional control in the dichotic listening: Evidence from younger and older Cantonese–English bilinguals. <em>The 15th International Symposium on Bilingualism (ISB15)</em>, San Sebastian, Spain. Oral Presentation.

**Liang, J.**, & Zhang, H. (2024). Effect of Mandarin speakers' musical aptitude on the perception of English vowels: An eye-tracking study. <em>CogSci 2024 Hong Kong Meetup</em>, Hong Kong. Poster Presentation.

**Liang, J.**, & Zhang, H. (2024). Effects of Mandarin speakers’ musical aptitude on the perception of English vowels: An eye-tracking study. <em>The 15th International Conference in Evolutionary Linguistics (CIEL 2024)</em>, Changsha, Hunan. Poster Presentation.

**Liang, J.**, & Zhang, H. (2023). Perception-production links in Mandarin speakers’ English vowels: A behavioral and eye-tracking study. <em>The 2nd National Symposium on Clinical Linguistics (NSCL2023)</em>, Jinan, Shandong. Oral Presentation.

**Liang, J.**, Jia, B., Liu, J., Li, X., & Zhang, H. (2023). Music experience enhances categorical perception of English vowels in Mandarin speakers. <em>The 14th International Conference in Evolutionary Linguistics (CIEL 2023)</em>, Hong Kong. Poster Presentation.

**Liang, J.**, Jia, B., Liu, J., Li, X., & Zhang, H. (2023). Music experience enhances categorical perception of English vowels in Mandarin speakers. <em>The 15th Phonetic Conference of China (PCC 2023)</em>, Shenzhen, Guangdong. Oral Presentation.



<h2>Research Experience</h2>

<ul class="research-list">
  <li>
    <strong>The effect of targeted melodic-speech training on Mandarin-speaking L2 learners’ perception of Cantonese level tones: Evidence from behavioral and neural tasks</strong><br>
    <span class="date">[Jun. 2025–Present]</span><br>
    Leading project (Supervisor: Dr. Quentin Zhen Qin)
    <ul class="inner-list">
      <li><strong>Conceptualization:</strong> Motivated the project through an in-depth literature review and identified key theoretical and methodological gaps.</li>
      <li><strong>Design:</strong> Built and deployed three training conditions in Gorilla (instructions, randomization, data export). Designed an EEG oddball paradigm and behavioral tasks in E-Prime (ABX discrimination task and a Sequence Recall Task), with triggers via StimTracker interfacing with Curry.</li>
      <li><strong>Data collection:</strong> Recruited and tested 27 Mandarin-speaking participants; coordinated sessions and ensured protocol adherence.</li>
      <li><strong>Data analysis:</strong> Curated pilot datasets and validated response/marker alignment. Preprocessed data in Python; analyzed and visualized results in R. Conducted ERP analyses and visualized mismatch negativity components in MATLAB (EEGLAB; ERPLAB packages).</li>
    </ul>
  </li>

  <li>
    <strong>Adult second-language learners’ consolidation of Cantonese tones during daytime naps: The role of prior knowledge</strong><br>
    <span class="date">[Jan. 2025–Present]</span><br>
    Assisted project (Supervisor: Dr. Quentin Zhen Qin)
    <ul class="inner-list">
      <li><strong>Project administration:</strong> Supported recruitment for a hard-to-reach population by distributing study posters on campus and assisting with online outreach (e.g., Facebook) to enroll non-tonal L1 English-speaking South Asian participants in Hong Kong.</li>
      <li><strong>Data collection:</strong> Ran sessions for 50 participants. Conducted in-lab EEG setup and recording preparation for nap sessions (cap fitting, gel injection, impedance/signal checks).</li>
      <li><strong>Data analysis:</strong> Performed sleep staging for EEG recording and curated participant-level sleep/behavior datasets. Analyzed behavioral data in R. Detected spindles/slow waves in Python (YASA) and related sleep metrics to learning outcomes using R regression models.</li>
      <li><strong>Dissemination:</strong> Prepared and submitted a first-author abstract to HISPhonCog 2026.</li>
      <li><strong>Training &amp; supervision:</strong> Trained a part-time research assistant on standardized procedures and data-collection protocols.</li>
    </ul>
  </li>

  <li>
    <strong>Enhancing the perception and recognition of spoken words in a second language: A cue-weighting approach</strong><br>
    <span class="date">[Oct. 2024–Present]</span><br>
    Assisted project (Supervisor: Dr. Quentin Zhen Qin)
    <ul class="inner-list">
      <li><strong>Project administration:</strong> Assisted with setup and testing of eye-tracking experiments (SR Research Experiment Builder and Data Viewer), including calibration/validation and output checks.</li>
      <li><strong>Data collection:</strong> Recruited and tested 60 participants; monitored completion/quality checks for a Gorilla-based online training program.</li>
      <li><strong>Data analysis:</strong> Cleaned and curated behavioral datasets; produced plots and summary statistics in R (e.g., ggplot2).</li>
      <li><strong>Dissemination:</strong> Provided feedback on poster and manuscript drafts. Co-authored a conference poster (ASA 2025) and contributed to a manuscript submitted to <em>Cognition</em>.</li>
    </ul>
  </li>

  <li>
    <strong>The role of bilingual experiences on attentional control in dichotic listening: Evidence from older Cantonese–English bilinguals</strong><br>
    <span class="date">[Sep. 2024–Nov. 2024]</span><br>
    Assisted project (Supervisor: Dr. Quentin Zhen Qin)
    <ul class="inner-list">
      <li><strong>Data collection:</strong> Recruited and tested 30 Cantonese-speaking older adults; coordinated lab sessions and maintained standardized procedures.</li>
      <li><strong>Dissemination:</strong> Provided feedback on the poster and preliminary data report; co-authored a poster presented at ISB15 and an abstract submitted to HISPhonCog 2026.</li>
    </ul>
  </li>

  <li>
    <strong>Benefits of melodic training on the production and perception of Cantonese level tones by Korean and Chinese older adults</strong><br>
    <span class="date">[Nov. 2023–Present]</span><br>
    Leading project (Supervisor: Dr. Hao Zhang)
    <ul class="inner-list">
      <li><strong>Conceptualization:</strong> Developed the training rationale and outcome measures based on a comprehensive literature review.</li>
      <li><strong>Design:</strong> Implemented a melodic height identification training program in JavaScript (<a href="https://www.jspsych.org/7.3/" target="_blank">jsPsych</a>) with tone identification/discrimination assessments. Implemented SpeechRecorder for production assessments.</li>
      <li><strong>Data collection:</strong> Recruited and tested 30 pilot participants (15 Korean; 15 Chinese older adults) and managed end-to-end session administration.</li>
      <li><strong>Data analysis:</strong> Curated and quality-checked production/perception datasets. Automated forced alignment with <a href="https://montreal-forced-aligner.readthedocs.io/en/latest/" target="_blank">Montreal Forced Aligner</a> and extracted F0 measures; quantified tone separability/hit rates and generated tone-overlap plots; transformed accuracy to RAUs and ran statistical analyses in R.</li>
      <li><strong>Dissemination:</strong> Prepared analysis figures and draft write-ups for ongoing manuscript development.</li>
    </ul>
  </li>

  <li>
    <strong>Perception–production links in Mandarin speakers’ English vowels: A behavioral and eye-tracking study</strong><br>
    <span class="date">[Jul. 2023–Jul. 2024]</span><br>
    Undergraduate thesis (Supervisor: Dr. Hao Zhang)
    <ul class="inner-list">
      <li><strong>Conceptualization:</strong> Conducted a comprehensive literature review; led end-to-end study planning and execution, including protocol development and timeline management.</li>
      <li><strong>Design:</strong> Designed eye-tracking experiments in SR Research Experiment Builder and developed perception/production stimuli in MATLAB (TANDEM-STRAIGHT); verified task logic and output formats.</li>
      <li><strong>Data collection:</strong> Recruited and tested 60 college students in eye-tracking and production sessions; ensured consistent session documentation.</li>
      <li><strong>Data analysis:</strong> Curated and documented datasets across modalities. Automated annotation using <a href="https://sppas.org/" target="_blank">SPPAS</a> and <a href="http://darla.dartmouth.edu/index" target="_blank">DARLA</a>; extracted F1/F2 in MATLAB (<a href="https://phonetics.ucla.edu/voicesauce/" target="_blank">VoiceSauce</a>). Analyzed fixation data with growth curve analysis models in R (<a href="http://www.eyetracking-r.com/" target="_blank">eyetrackingR</a>; <a href="https://cran.r-project.org/web/packages/lme4/index.html" target="_blank">lme4</a>; <a href="https://ggplot2.tidyverse.org/" target="_blank">ggplot2</a>), and computed boundary measures in Python; produced publication-ready figures.</li>
      <li><strong>Dissemination:</strong> Wrote the manuscript and disseminated findings via a peer-reviewed journal publication and conference posters (CIEL 2024; CogSci 2024 Hong Kong Meetup).</li>
    </ul>
  </li>

  <li>
    <strong>Music experience enhances categorical perception of English vowels in Mandarin speakers</strong><br>
    <span class="date">[Mar. 2023–Jun. 2023]</span><br>
    Leading project (Supervisor: Dr. Hao Zhang)
    <ul class="inner-list">
      <li><strong>Conceptualization:</strong> Led project conceptualization and developed the study motivation.</li>
      <li><strong>Project administration:</strong> Coordinated team workflow; assigned tasks based on members’ strengths and provided guidance throughout.</li>
      <li><strong>Design:</strong> Synthesized and manipulated stimuli in MATLAB (TANDEM-STRAIGHT) and implemented the experiment in <a href="https://www.psychopy.org/" target="_blank">PsychoPy</a>; verified task outputs and data logging.</li>
      <li><strong>Data collection:</strong> Recruited and tested 24 college students; coordinated scheduling and session documentation.</li>
      <li><strong>Data analysis:</strong> Curated datasets, conducted statistical analyses in Python, and prepared a summary report with visualizations.</li>
      <li><strong>Funding:</strong> Secured university-level undergraduate research funding via a successful proposal.</li>
      <li><strong>Dissemination:</strong> Designed the project poster and presented at CIEL 2023 (poster).</li>
    </ul>
  </li>
</ul>


<h2>Research Experience</h2>

<ul class="research-list">
    <li>
        <strong>Adult Second-language Learners’ Consolidation of Cantonese Tones during Daytime Naps: the Role of Prior Knowledge</strong><br>
        <span class="date">[2025.01-Present]</span>
        <ul class="inner-list">
            <li>Recruited and conducted experiments with 15 participants.</li>
            <li>Analyzed EEG and behavioral data.</li>
        </ul>
    </li>
    <li>
        <strong>Enhancing the Perception and Recognition of Spoken Words in a Second Language: A Cue-Weighting Approach</strong><br>
        <span class="date">[2024.10-Present]</span>
        <ul class="inner-list">
            <li>Assisted in the setup of eye-tracking experiments.</li>
            <li>Recruited and conducted experiments with 60 participants.</li>
        </ul>
    </li>
    <li>
        <strong>Effects of Tone Types and Bilingual Experiences on Forced-attention Dichotic Task in Cantonese-speaking Older Adults</strong><br>
        <span class="date">[2024.09-2024.11]</span>
        <ul class="inner-list">
            <li>Recruited and conducted experiments with 20 Cantonese-speaking older adults.</li>
        </ul>
    </li>
    <li>
        <strong>Efficacy of Melodic Training and Sleep-mediated Memory Consolidation in Learning Cantonese Level Tones by Mandarin-speaking Younger Adults</strong><br>
        <span class="date">[2024.04-Present]</span>
        <ul class="inner-list">
            <li>Conducted extensive literature review.</li>
            <li>Recruited 80 Mandarin-speaking college students to engage in the music training program and associated assessments, developed in the <a href="#melodicTraining2023">previous study</a>.</li>
        </ul>
    </li>
    <li>
        <strong>Benefits of Melodic Training on the Production and Perception of Cantonese Level Tones by Korean and Chinese Older Adults</strong><br>
        <span class="date">[2023.11-Present]</span>
        <ul class="inner-list">
            <li>Conducted comprehensive literature review.</li>
            <li id="melodicTraining2023">Developed and implemented a Melodic Height Identification Training program and associated assessments (identification and discrimination tests), utilizing JavaScript (<a href="https://www.jspsych.org/7.3/" target="_blank">jsPsych</a>).</li>
            <li>Recruited and conducted experiments with 30 participants, including 15 Korean and 15 Chinese older adults.</li>
            <li>Employed <a href="https://montreal-forced-aligner.readthedocs.io/en/latest/" target="_blank">Montreal Forced Aligner</a> for automatic annotation of production data, and automatically extracted of F0 values.</li>
            <li>Analyzed participants' tone differentiability and hit rate to evaluate production performance and generated tone overlap plots.</li>
            <li>Transformed perception data (accuracy percentages) into rationalized arcsine units (RAUs) for statistical analysis.</li>
            <li>Performed statistical analysis</li>
        </ul>
    </li>
    <li>
        <strong>Perception-Production Links in Mandarin Speakers' English Vowels: A Behavioral and Eye-tracking Study</strong><br>
        <span class="date">[2023.07-2024.07]</span>
        <ul class="inner-list">
            <li>Conducted thorough literature review and synthesized experimental stimuli.</li>
            <li>Designed eye-tracking experiments with <a href="https://www.sr-research.com/experiment-builder/" target="_blank">Experiment Builder</a>.</li>
            <li>Recruited and conducted eye-tracking experiments with 60 college students.</li>
            <li>Employed automatic annotation for production data using <a href="https://sppas.org/" target="_blank">SPPAS</a> and <a href="http://darla.dartmouth.edu/index" target="_blank">DARLA</a>, and automatic extraction of F1 and F2 values in MATLAB (<a href="https://phonetics.ucla.edu/voicesauce/" target="_blank">VoiceSauce</a>).</li>
            <li>Calculated participants' boundary width in Python to assess perception performance.</li>
            <li>Processed eye-movement data in R (<a href="http://www.eyetracking-r.com/" target="_blank">eyetrackingR</a>) and calculated the difference between the empirical log-transformed proportions of target and competitor fixations.</li>
            <li>Calculated participants' Pillai score in R to measure vowel overlap and plotted vowel overlap using F1 and F2 values in R (<a href="https://ggplot2.tidyverse.org/" target="_blank">ggplot2</a>).</li>
            <li>Conducted LME and Growth Curve Analysis (GCA) in R (<a href="https://cran.r-project.org/web/packages/lme4/index.html" target="_blank">lme4</a>).</li>
            <li>Wrote the manuscript.</li>
        </ul>
    </li>
    <li>
        <strong>Music Experience Enhances Categorical Perception of English Vowels in Mandarin Speakers</strong><br>
        <span class="date">[2023.03-2023.06]</span><br>
        <ul class="inner-list">
            <li>Conducted literature review, synthesized and manipulated experimental stimuli using MATLAB (<a href="https://ieeexplore.ieee.org/document/4518514" target="_blank">TANDEM-STRAIGHT</a>).</li>
            <li>Recruited 24 college students for participation.</li>
            <li>Designed and executed experiments in <a href="https://www.psychopy.org/" target="_blank">PsychoPy</a>.</li>
            <li>Performed ANOVA and Pearson correlation analysis in Python (<a href="https://pypi.org/project/pandas/" target="_blank">Pandas</a>).</li>
            <li>Wrote the manuscript.</li>
        </ul>
    </li>
</ul>



## Service
- Research assistant at Hong Kong University of Science and Technology [2024-present]
- Research assistant at Shandong University [2023-2024]


## Awards
- College Students' Innovative and Entrepreneurial Training Program Funding Supported by Shandong University [2022]
- The Third-Class Undergraduate Academic Scholarship [2021]













## Skills
- Programming: Python, R, JavaScript and MATLAB
- Language proficiency: Mandarin (native), Cantonese (native) and English (IELTS score: 8.0)



